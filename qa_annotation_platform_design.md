# -*- encoding: utf-8 -*-
"""
@author: chenda14
@time: 2025-12-25
@email: chenda14@jd.com
@desc: OxyGent QAæ ‡æ³¨å¹³å°æ¶æ„è®¾è®¡æ–¹æ¡ˆ
"""

# OxyGent QAæ ‡æ³¨å¹³å°æ¶æ„è®¾è®¡æ–¹æ¡ˆ v2.1

## ğŸ“‹ ä¸€ã€éœ€æ±‚åˆ†æä¸æ•°æ®æºç¡®è®¤

### 1.1 æ ¸å¿ƒç›®æ ‡

æ„å»ºä¸€å¥—åŸºäºæ¶ˆæ¯é˜Ÿåˆ—çš„QAæ•°æ®æ ‡æ³¨Pipelineï¼Œä»OxyGentæ¡†æ¶çš„å¯¹è¯è®°å½•ä¸­æå–é«˜è´¨é‡è®­ç»ƒè¯­æ–™ã€‚

### 1.2 æ•°æ®æºç¡®è®¤

é€šè¿‡å¯¹å®é™…ESæ•°æ®çš„åˆ†æï¼Œç¡®è®¤å„è¡¨çš„å­˜å‚¨å†…å®¹å’Œç”¨é€”ï¼š

| è¡¨å | å†™å…¥æ—¶æœº | ä¸»è¦å†…å®¹ | é€‚ç”¨åœºæ™¯ |
|------|---------|---------|---------|
| **`{app}_trace`** | `caller_category == "user"` | ç«¯åˆ°ç«¯å®Œæ•´å¯¹è¯ï¼ˆinput + outputï¼‰ | **P0ä¼˜å…ˆçº§ï¼šç«¯åˆ°ç«¯QA** |
| **`{app}_node`** | æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œæ—¶ | æ‰€æœ‰èŠ‚ç‚¹çš„è°ƒç”¨è®°å½•ï¼ˆcaller/callee/input/outputï¼‰ | **P1/P2/P3ï¼šAgenté—´QA** |
| **`{app}_history`** | `is_save_history=True` | QAç²¾ç®€è®°å½•ï¼ˆsession_name + memoryï¼‰ | è¾…åŠ©æ•°æ®æº |
| **`{app}_message`** | `is_stored=True` | å‰ç«¯æ¶ˆæ¯æµ | æš‚ä¸é‡‡é›† |

### 1.3 æ•°æ®æºå­—æ®µè¯¦è§£

#### traceè¡¨ï¼ˆç«¯åˆ°ç«¯å¯¹è¯ï¼‰

```json
{
  "trace_id": "xxx",           // ä¼šè¯IDï¼ˆå…³é”®ï¼šç”¨äºå…³è”å­èŠ‚ç‚¹ï¼‰
  "group_id": "xxx",           // å¤šè½®å¯¹è¯ç»„ID
  "request_id": "xxx",         // è¯·æ±‚ID
  "callee": "master_agent",    // è¢«è°ƒç”¨çš„Agent
  "input": "{\"query\": \"...\", \"full_memory\": [...]}",  // å®Œæ•´è¾“å…¥
  "output": "æœ€ç»ˆå›ç­”å†…å®¹",     // æœ€ç»ˆè¾“å‡º
  "shared_data": "{}",         // å…±äº«æ•°æ®
  "create_time": "2025-..."    // åˆ›å»ºæ—¶é—´
}
```

#### nodeè¡¨ï¼ˆAgenté—´è°ƒç”¨ï¼‰

```json
{
  "node_id": "xxx",            // èŠ‚ç‚¹ID
  "trace_id": "xxx",           // å…³è”çš„ä¼šè¯IDï¼ˆå…³é”®ï¼šå»ºç«‹å½’å±å…³ç³»ï¼‰
  "caller": "master_agent",    // è°ƒç”¨è€…
  "callee": "time_agent",      // è¢«è°ƒç”¨è€…
  "call_stack": ["user", "master_agent", "time_agent"],  // è°ƒç”¨é“¾
  "father_node_id": "xxx",     // çˆ¶èŠ‚ç‚¹IDï¼ˆå…³é”®ï¼šå»ºç«‹å±‚çº§å…³ç³»ï¼‰
  "input": "{...}",            // è¾“å…¥å‚æ•°
  "output": "æ‰§è¡Œç»“æœ",         // è¾“å‡ºç»“æœ
  "state": 3,                  // çŠ¶æ€ï¼ˆ3=COMPLETEDï¼‰
  "node_type": "agent",        // èŠ‚ç‚¹ç±»å‹ï¼ˆagent/tool/llmï¼‰
  "create_time": "2025-..."
}
```

### 1.4 QAä¼˜å…ˆçº§å®šä¹‰

```mermaid
graph TB
    subgraph "ä¼˜å…ˆçº§å±‚çº§"
        P0["ğŸ”´ P0 - ç«¯åˆ°ç«¯QA"]
        P1["ğŸŸ  P1 - Userâ†’Master Agent"]
        P2["ğŸŸ¡ P2 - Agentâ†’Agent"]
        P3["ğŸŸ¢ P3 - Agentâ†’Tool"]
    end
    
    P0 --> |"traceè¡¨<br/>caller_category=user"| T0["ç”¨æˆ·é—®é¢˜ â†’ æœ€ç»ˆç­”æ¡ˆ"]
    P1 --> |"nodeè¡¨<br/>caller=user"| T1["ç”¨æˆ· â†’ ä¸»Agent"]
    P2 --> |"nodeè¡¨<br/>caller_category=agent<br/>callee_category=agent"| T2["ä¸»Agent â†’ å­Agent"]
    P3 --> |"nodeè¡¨<br/>callee_category=tool"| T3["Agent â†’ å·¥å…·è°ƒç”¨"]
```

**ä¼˜å…ˆçº§åˆ¤æ–­è§„åˆ™è¯´æ˜ï¼š**

| ä¼˜å…ˆçº§ | æ¡ä»¶ | æ•°æ®æº | åœºæ™¯æè¿° |
|--------|------|--------|----------|
| P0 | `caller_category == "user"` ä¸”åœ¨ trace è¡¨ | traceè¡¨ | ç”¨æˆ·å‘èµ·çš„å®Œæ•´å¯¹è¯ï¼ŒåŒ…å«æœ€ç»ˆç­”æ¡ˆ |
| P1 | `caller == "user"` ä¸”åœ¨ node è¡¨ | nodeè¡¨ | ç”¨æˆ·ç›´æ¥è°ƒç”¨æŸä¸ªAgentçš„è®°å½• |
| P2 | `caller_category == "agent"` ä¸” `callee_category == "agent"` | nodeè¡¨ | Agentä¹‹é—´çš„è°ƒç”¨ |
| P3 | `callee_category == "tool"` æˆ– `node_type == "tool"` | nodeè¡¨ | Agentè°ƒç”¨å·¥å…·çš„è®°å½• |

### 1.5 å½’å±å…³ç³»è®¾è®¡

**æ ¸å¿ƒæ¦‚å¿µï¼šä¸€ä¸ªç«¯åˆ°ç«¯å¯¹è¯ï¼ˆP0ï¼‰ä¼šè§¦å‘å¤šä¸ªå­è°ƒç”¨ï¼ˆP1-P3ï¼‰ï¼Œå®ƒä»¬é€šè¿‡ `trace_id` å»ºç«‹å½’å±å…³ç³»ã€‚**

```mermaid
graph TD
    subgraph "ä¸€æ¬¡å®Œæ•´å¯¹è¯çš„å½’å±å…³ç³»"
        E2E["ğŸ“ ç«¯åˆ°ç«¯QA (P0)<br/>trace_id: abc123<br/>qa_id: qa_001"]
        
        E2E --> N1["Agentè°ƒç”¨-1 (P2)<br/>node_id: n001<br/>parent_qa_id: qa_001"]
        E2E --> N2["Agentè°ƒç”¨-2 (P2)<br/>node_id: n002<br/>parent_qa_id: qa_001"]
        
        N1 --> T1["Toolè°ƒç”¨-1 (P3)<br/>node_id: n003<br/>parent_qa_id: qa_001"]
        N1 --> T2["Toolè°ƒç”¨-2 (P3)<br/>node_id: n004<br/>parent_qa_id: qa_001"]
        
        N2 --> T3["Toolè°ƒç”¨-3 (P3)<br/>node_id: n005<br/>parent_qa_id: qa_001"]
    end
    
    style E2E fill:#ff6b6b,color:#fff
    style N1 fill:#ffa94d,color:#fff
    style N2 fill:#ffa94d,color:#fff
    style T1 fill:#69db7c,color:#fff
    style T2 fill:#69db7c,color:#fff
    style T3 fill:#69db7c,color:#fff
```

**å½’å±å…³ç³»å»ºç«‹è§„åˆ™ï¼š**

1. **ä» trace è¡¨å¯¼å…¥æ—¶**ï¼š
   - å…ˆåˆ›å»ºç«¯åˆ°ç«¯QAï¼ˆP0ï¼‰ï¼Œç”Ÿæˆ `qa_id`
   - å†æŸ¥è¯¢è¯¥ `trace_id` ä¸‹çš„æ‰€æœ‰ node è®°å½•
   - å°†è¿™äº› node çš„ `parent_qa_id` è®¾ç½®ä¸ºç«¯åˆ°ç«¯QAçš„ `qa_id`

2. **ä» node è¡¨å•ç‹¬å¯¼å…¥æ—¶**ï¼š
   - å¦‚æœè¯¥ `trace_id` å¯¹åº”çš„ç«¯åˆ°ç«¯QAå·²å­˜åœ¨ï¼Œå…³è”åˆ°è¯¥ `parent_qa_id`
   - å¦‚æœä¸å­˜åœ¨ï¼Œ`parent_qa_id` ä¸ºç©º

3. **å®æ—¶Hooké‡‡é›†æ—¶**ï¼š
   - æ¯ä¸ªèŠ‚ç‚¹å®Œæˆæ—¶ç«‹å³é‡‡é›†
   - é€šè¿‡ `trace_id` åœ¨åç»­LLMå¤„ç†é˜¶æ®µå»ºç«‹å…³è”

---

## ğŸ—ï¸ äºŒã€æ•´ä½“æ¶æ„è®¾è®¡

### 2.1 ç³»ç»Ÿæ¶æ„å›¾

```mermaid
flowchart TB
    subgraph DataSource["ğŸ“¦ æ•°æ®æºå±‚"]
        ES_Trace["ES: traceè¡¨"]
        ES_Node["ES: nodeè¡¨"]
        RealTimeHook["å®æ—¶Hook"]
    end
    
    subgraph MQLayer["ğŸ“¬ æ¶ˆæ¯é˜Ÿåˆ—å±‚ (å¯åˆ‡æ¢)"]
        subgraph MQImpl["MQå®ç°"]
            Redis["Redis Streams"]
            RabbitMQ["RabbitMQ"]
            Kafka["Kafka"]
        end
        
        T1["qa:raw"]
        T2["qa:processed"]
        T3["qa:pending"]
        T4["qa:review"]
        T5["qa:knowledge"]
        T6["qa:dead_letter"]
    end
    
    subgraph ProcessLayer["âš™ï¸ å¤„ç†å±‚"]
        Collector["QAé‡‡é›†å™¨"]
        LLMProc["LLMå¤„ç†å™¨"]
        Dispatcher["ä»»åŠ¡åˆ†é…å™¨"]
        ReviewHandler["å®¡æ ¸å¤„ç†å™¨"]
        KBPublisher["çŸ¥è¯†åº“å‘å¸ƒå™¨"]
    end
    
    subgraph PlatformLayer["ğŸ–¥ï¸ æ ‡æ³¨å¹³å°å±‚"]
        WebUI["Webå‰ç«¯"]
        TaskAPI["ä»»åŠ¡API"]
        UserMgmt["ç”¨æˆ·ç®¡ç†"]
        StatsAPI["ç»Ÿè®¡API"]
    end
    
    subgraph StorageLayer["ğŸ’¾ å­˜å‚¨å±‚"]
        ES_Task["ES: qa_task"]
        ES_Anno["ES: qa_annotation"]
        ES_User["ES: qa_user"]
    end
    
    %% æ•°æ®æµ
    ES_Trace --> Collector
    ES_Node --> Collector
    RealTimeHook --> Collector
    
    Collector --> T1
    T1 --> LLMProc
    LLMProc --> T2
    T2 --> Dispatcher
    Dispatcher --> T3
    
    T3 --> WebUI
    WebUI --> T4
    T4 --> ReviewHandler
    ReviewHandler --> T5
    T5 --> KBPublisher
    
    %% æ­»ä¿¡é˜Ÿåˆ—
    LLMProc -.->|å¤„ç†å¤±è´¥| T6
    Dispatcher -.->|åˆ†é…å¤±è´¥| T6
    
    TaskAPI --> ES_Task
    TaskAPI --> ES_Anno
    UserMgmt --> ES_User
```

---

## ğŸ“¬ ä¸‰ã€æ¶ˆæ¯é˜Ÿåˆ—Topicè®¾è®¡ä¸Pipelineæµè½¬

### 3.1 Topicå®šä¹‰

| Topicåç§° | æè¿° | ç”Ÿäº§è€… | æ¶ˆè´¹è€… | æ¶ˆæ¯æ ¼å¼ |
|-----------|------|--------|--------|----------|
| `qa:raw` | åŸå§‹QAæ•°æ® | Hooké‡‡é›†å™¨ / å†å²å¯¼å…¥å™¨ | LLMå¤„ç†å™¨ | RawQAMessage |
| `qa:processed` | LLMå¤„ç†åçš„æ•°æ® | LLMå¤„ç†å™¨ | ä»»åŠ¡åˆ†é…å™¨ | ProcessedQAMessage |
| `qa:pending` | å¾…æ ‡æ³¨ä»»åŠ¡ | ä»»åŠ¡åˆ†é…å™¨ | å‰ç«¯è½®è¯¢ / WebSocket | TaskMessage |
| `qa:review` | å¾…å®¡æ ¸ä»»åŠ¡ | æ ‡æ³¨æäº¤ | å®¡æ ¸å¤„ç†å™¨ | ReviewMessage |
| `qa:knowledge` | å¾…å…¥çŸ¥è¯†åº“ | å®¡æ ¸å¤„ç†å™¨ | çŸ¥è¯†åº“å‘å¸ƒå™¨ | KnowledgeMessage |
| `qa:dead_letter` | å¤„ç†å¤±è´¥çš„æ¶ˆæ¯ | å„å¤„ç†å™¨ | è¿ç»´ç›‘æ§ | ErrorMessage |

### 3.2 Pipelineæµè½¬è¯¦è§£

```mermaid
sequenceDiagram
    participant Source as æ•°æ®æº
    participant Raw as qa:raw
    participant LLM as LLMå¤„ç†å™¨
    participant Proc as qa:processed
    participant Disp as ä»»åŠ¡åˆ†é…å™¨
    participant Pend as qa:pending
    participant UI as æ ‡æ³¨ç•Œé¢
    participant Rev as qa:review
    participant Handler as å®¡æ ¸å¤„ç†å™¨
    participant KB as qa:knowledge
    participant Dead as qa:dead_letter
    
    Note over Source,Dead: é˜¶æ®µ1: æ•°æ®é‡‡é›†
    Source->>Raw: å‘å¸ƒ RawQAMessage
    
    Note over Source,Dead: é˜¶æ®µ2: LLMé¢„å¤„ç†
    Raw->>LLM: æ¶ˆè´¹æ¶ˆæ¯
    alt å¤„ç†æˆåŠŸ
        LLM->>Proc: å‘å¸ƒ ProcessedQAMessage
    else å¤„ç†å¤±è´¥ï¼ˆé‡è¯•3æ¬¡åï¼‰
        LLM->>Dead: å‘å¸ƒåˆ°æ­»ä¿¡é˜Ÿåˆ—
    end
    
    Note over Source,Dead: é˜¶æ®µ3: ä»»åŠ¡åˆ†é…
    Proc->>Disp: æ¶ˆè´¹æ¶ˆæ¯
    Disp->>Disp: æŸ¥é‡ã€åˆ†é…æ ‡æ³¨è€…ã€è®¾ç½®è¿‡æœŸæ—¶é—´
    Disp->>Pend: å‘å¸ƒ TaskMessage
    
    Note over Source,Dead: é˜¶æ®µ4: äººå·¥æ ‡æ³¨
    Pend->>UI: å‰ç«¯è·å–ä»»åŠ¡
    UI->>UI: æ ‡æ³¨è€…ç¼–è¾‘
    UI->>Rev: æäº¤æ ‡æ³¨ç»“æœ
    
    Note over Source,Dead: é˜¶æ®µ5: å®¡æ ¸æµç¨‹
    Rev->>Handler: æ¶ˆè´¹æ¶ˆæ¯
    alt å®¡æ ¸é€šè¿‡ + éœ€å…¥çŸ¥è¯†åº“
        Handler->>KB: å‘å¸ƒåˆ°çŸ¥è¯†åº“é˜Ÿåˆ—
    else å®¡æ ¸æ‹’ç»
        Handler->>Pend: é‡æ–°åˆ†é…
    end
```

### 3.3 å„é˜¶æ®µæ¶ˆæ¯æ ¼å¼å®šä¹‰

#### RawQAMessageï¼ˆåŸå§‹QAæ¶ˆæ¯ï¼‰

```python
@dataclass
class RawQAMessage:
    """åŸå§‹QAæ•°æ®æ¶ˆæ¯"""
    qa_id: str                    # QAå”¯ä¸€æ ‡è¯†
    batch_id: str                 # æ‰¹æ¬¡IDï¼ˆå¯¼å…¥æ—¶ç”Ÿæˆï¼‰
    
    # QAå†…å®¹
    question: str                 # é—®é¢˜
    answer: str                   # ç­”æ¡ˆ
    qa_hash: str                  # QAå†…å®¹çš„MD5ï¼ˆç”¨äºå»é‡ï¼‰
    
    # æ¥æºè¿½æº¯
    source_type: str              # e2e/user_agent/agent_agent/agent_tool
    source_trace_id: str          # åŸå§‹trace_id
    source_node_id: str           # åŸå§‹node_idï¼ˆå¯é€‰ï¼‰
    source_group_id: str          # åŸå§‹group_id
    
    # è°ƒç”¨ä¿¡æ¯
    caller: str                   # è°ƒç”¨è€…
    callee: str                   # è¢«è°ƒç”¨è€…
    call_chain: List[str]         # å®Œæ•´è°ƒç”¨é“¾
    
    # å½’å±å…³ç³»
    parent_qa_id: str             # çˆ¶QAçš„IDï¼ˆç«¯åˆ°ç«¯QAçš„IDï¼‰
    
    # ä¼˜å…ˆçº§
    priority: int                 # 0-3ï¼Œæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
    
    # æ—¶é—´
    created_at: str               # åˆ›å»ºæ—¶é—´
```

#### ProcessedQAMessageï¼ˆå¤„ç†åçš„QAæ¶ˆæ¯ï¼‰

```python
@dataclass
class ProcessedQAMessage(RawQAMessage):
    """LLMå¤„ç†åçš„QAæ¶ˆæ¯"""
    # ç»§æ‰¿RawQAMessageçš„æ‰€æœ‰å­—æ®µ
    
    # LLMå¤„ç†ç»“æœ
    llm_summary: str              # LLMç”Ÿæˆçš„æ‘˜è¦
    llm_quality_score: float      # è´¨é‡è¯„åˆ† 0.0-1.0
    llm_suggested_category: str   # å»ºè®®çš„åˆ†ç±»
    llm_is_valid: bool            # æ˜¯å¦ä¸ºæœ‰æ•ˆQA
    llm_issues: List[str]         # å‘ç°çš„é—®é¢˜åˆ—è¡¨
    
    # å¤„ç†çŠ¶æ€
    processed_at: str             # å¤„ç†æ—¶é—´
    retry_count: int              # é‡è¯•æ¬¡æ•°
```

#### TaskMessageï¼ˆä»»åŠ¡æ¶ˆæ¯ï¼‰

```python
@dataclass
class TaskMessage:
    """æ ‡æ³¨ä»»åŠ¡æ¶ˆæ¯"""
    task_id: str                  # ä»»åŠ¡ID
    qa_id: str                    # å…³è”çš„QA ID
    
    # ä»»åŠ¡å†…å®¹ï¼ˆå¤åˆ¶è‡ªProcessedQAMessageï¼‰
    question: str
    answer: str
    llm_summary: str
    llm_quality_score: float
    
    # å½’å±å…³ç³»
    parent_task_id: str           # çˆ¶ä»»åŠ¡IDï¼ˆå¯¹åº”ç«¯åˆ°ç«¯QAï¼‰
    source_trace_id: str
    
    # åˆ†é…ä¿¡æ¯
    assigned_to: str              # åˆ†é…ç»™è°
    assigned_at: str              # åˆ†é…æ—¶é—´
    expire_at: str                # è¿‡æœŸæ—¶é—´
    
    # çŠ¶æ€
    status: str                   # pending/assigned/annotated
    priority: int
```

### 3.4 Pipelineæµè½¬è§„åˆ™

#### 3.4.1 LLMå¤„ç†å™¨è§„åˆ™

**è¾“å…¥**ï¼š`qa:raw` ä¸­çš„ `RawQAMessage`

**å¤„ç†é€»è¾‘**ï¼š
1. **å»é‡æ£€æŸ¥**ï¼šæ ¹æ® `qa_hash` æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
2. **LLMåˆ†æ**ï¼šè°ƒç”¨é…ç½®çš„LLMæ¨¡å‹è¿›è¡Œè´¨é‡è¯„ä¼°
3. **å½’å±å…³ç³»è¡¥å…¨**ï¼šæ ¹æ® `source_trace_id` æŸ¥æ‰¾å¹¶å…³è” `parent_qa_id`

**è¾“å‡ºè§„åˆ™**ï¼š
- å¤„ç†æˆåŠŸï¼šå‘å¸ƒåˆ° `qa:processed`
- é‡å¤æ•°æ®ï¼šä¸¢å¼ƒï¼Œè®°å½•æ—¥å¿—
- å¤„ç†å¤±è´¥ï¼šé‡è¯•3æ¬¡åå‘å¸ƒåˆ° `qa:dead_letter`

**å¯é€‰é…ç½®**ï¼š
```json
{
  "llm_processor": {
    "enabled": true,           // æ˜¯å¦å¯ç”¨LLMå¤„ç†
    "skip_if_disabled": true,  // ç¦ç”¨æ—¶ç›´æ¥è½¬å‘åˆ°ä¸‹ä¸€é˜¶æ®µ
    "model": "default_llm",
    "max_retries": 3,
    "retry_delay_seconds": 5
  }
}
```

#### 3.4.2 ä»»åŠ¡åˆ†é…å™¨è§„åˆ™

**è¾“å…¥**ï¼š`qa:processed` ä¸­çš„ `ProcessedQAMessage`

**å¤„ç†é€»è¾‘**ï¼š
1. **è´¨é‡è¿‡æ»¤**ï¼š`llm_quality_score < 0.3` çš„ä»»åŠ¡æ ‡è®°ä¸ºä½è´¨é‡
2. **ä¼˜å…ˆçº§æ’åº**ï¼šæŒ‰ `priority` æ’åº
3. **æ ‡æ³¨è€…é€‰æ‹©**ï¼šæ ¹æ®ä»¥ä¸‹è§„åˆ™é€‰æ‹©ï¼š
   - ä¼˜å…ˆåˆ†é…ç»™æ“…é•¿è¯¥ç±»åˆ«çš„æ ‡æ³¨è€…
   - è€ƒè™‘å½“å‰å·¥ä½œé‡å‡è¡¡
   - è€ƒè™‘æ ‡æ³¨è€…çš„å†å²è´¨é‡
4. **è®¾ç½®è¿‡æœŸæ—¶é—´**ï¼šé»˜è®¤24å°æ—¶

**è¾“å‡ºè§„åˆ™**ï¼š
- åˆ†é…æˆåŠŸï¼šå‘å¸ƒåˆ° `qa:pending`ï¼ŒåŒæ—¶å†™å…¥ `qa_task` è¡¨
- æ— å¯ç”¨æ ‡æ³¨è€…ï¼šå»¶è¿Ÿé‡è¯•

#### 3.4.3 å®¡æ ¸å¤„ç†å™¨è§„åˆ™

**è¾“å…¥**ï¼š`qa:review` ä¸­çš„ `ReviewMessage`

**å¤„ç†é€»è¾‘**ï¼š
1. è¯»å–å®¡æ ¸ç»“æœ
2. æ›´æ–°ä»»åŠ¡çŠ¶æ€

**è¾“å‡ºè§„åˆ™**ï¼š
- å®¡æ ¸é€šè¿‡ + éœ€å…¥çŸ¥è¯†åº“ï¼šå‘å¸ƒåˆ° `qa:knowledge`
- å®¡æ ¸é€šè¿‡ + ä¸éœ€å…¥åº“ï¼šç›´æ¥å½’æ¡£
- å®¡æ ¸æ‹’ç»ï¼šå‘å¸ƒåˆ° `qa:pending` é‡æ–°åˆ†é…

---

## ğŸ¯ å››ã€ä¼˜å…ˆçº§ä¸å½’å±å…³ç³»è¯¦ç»†è®¾è®¡

### 4.1 ä¼˜å…ˆçº§è®¡ç®—é€»è¾‘

```python
def calculate_priority(oxy_request: OxyRequest) -> int:
    """
    è®¡ç®—QAå¯¹çš„ä¼˜å…ˆçº§
    
    ä¼˜å…ˆçº§è§„åˆ™ï¼š
    - P0 (0): ç«¯åˆ°ç«¯å¯¹è¯ï¼Œç”¨æˆ·å‘èµ·ä¸”æœ‰å®Œæ•´å›ç­”
    - P1 (1): ç”¨æˆ·ç›´æ¥è°ƒç”¨Agent
    - P2 (2): Agentè°ƒç”¨Agent
    - P3 (3): Agentè°ƒç”¨Tool
    
    è¿”å›å€¼è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
    """
    caller_category = oxy_request.caller_category
    callee_category = oxy_request.callee_category
    caller = oxy_request.caller
    
    # P0: ç”¨æˆ·å‘èµ·çš„è°ƒç”¨ï¼Œä¸”è¢«è°ƒç”¨è€…æ˜¯Agent
    if caller_category == "user" and callee_category == "agent":
        # åˆ¤æ–­æ˜¯å¦æ˜¯is_masterçš„agentï¼ˆä¸»agentï¼‰
        if len(oxy_request.call_stack) == 2:  # ["user", "master_agent"]
            return 0  # ç«¯åˆ°ç«¯
        return 1  # ç”¨æˆ·ç›´æ¥è°ƒç”¨å­Agent
    
    # P1: ç”¨æˆ·è°ƒç”¨ï¼ˆéAgentæƒ…å†µï¼‰
    if caller == "user":
        return 1
    
    # P2: Agentè°ƒç”¨Agent
    if caller_category == "agent" and callee_category == "agent":
        return 2
    
    # P3: è°ƒç”¨Toolæˆ–å…¶ä»–
    return 3
```

### 4.2 å½’å±å…³ç³»å»ºç«‹æœºåˆ¶

#### 4.2.1 å®æ—¶Hooké‡‡é›†æ—¶

```mermaid
flowchart TD
    A[èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ] --> B{æ˜¯ç«¯åˆ°ç«¯å¯¹è¯?}
    B -->|æ˜¯| C[ç”Ÿæˆqa_idä½œä¸ºparent]
    B -->|å¦| D[æŸ¥æ‰¾åŒtrace_idçš„P0ä»»åŠ¡]
    
    C --> E[å‘å¸ƒåˆ°qa:raw<br/>parent_qa_idä¸ºç©º]
    D --> F{æ‰¾åˆ°P0ä»»åŠ¡?}
    F -->|æ˜¯| G[è®¾ç½®parent_qa_id]
    F -->|å¦| H[parent_qa_idä¸ºç©º<br/>åç»­å¤„ç†æ—¶è¡¥å…¨]
    
    G --> I[å‘å¸ƒåˆ°qa:raw]
    H --> I
```

**å®æ—¶Hookæ— æ³•ç›´æ¥çŸ¥é“parent_qa_idçš„é—®é¢˜è§£å†³æ–¹æ¡ˆï¼š**

ç”±äºå®æ—¶Hookæ˜¯åœ¨æ¯ä¸ªèŠ‚ç‚¹å®Œæˆæ—¶è§¦å‘ï¼Œæ­¤æ—¶å¯èƒ½ï¼š
1. ç«¯åˆ°ç«¯ä»»åŠ¡å°šæœªå®Œæˆï¼ˆå­ä»»åŠ¡å…ˆå®Œæˆï¼‰
2. æ— æ³•çŸ¥é“æœ€ç»ˆçš„parent_qa_id

**è§£å†³æ–¹æ¡ˆï¼šå»¶è¿Ÿå…³è”**

```python
class QACollectorHook:
    async def on_node_completed(self, oxy_request, oxy_response):
        qa_data = self._build_qa_data(oxy_request, oxy_response)
        
        # å¦‚æœæ˜¯ç«¯åˆ°ç«¯å¯¹è¯ï¼Œè®°å½•trace_idä¸qa_idçš„æ˜ å°„
        if qa_data["source_type"] == "e2e":
            await self._cache_trace_mapping(
                trace_id=qa_data["source_trace_id"],
                qa_id=qa_data["qa_id"]
            )
            qa_data["parent_qa_id"] = ""  # ç«¯åˆ°ç«¯ä»»åŠ¡æœ¬èº«æ²¡æœ‰parent
        else:
            # å°è¯•ä»ç¼“å­˜è·å–parent_qa_id
            parent_qa_id = await self._get_cached_parent(qa_data["source_trace_id"])
            qa_data["parent_qa_id"] = parent_qa_id or ""
        
        await self.mq.publish("raw", qa_data)
    
    async def _cache_trace_mapping(self, trace_id: str, qa_id: str):
        """ç¼“å­˜trace_idåˆ°qa_idçš„æ˜ å°„ï¼Œç”¨äºå»ºç«‹å½’å±å…³ç³»"""
        cache_key = f"qa:trace_parent:{trace_id}"
        await self.redis.setex(cache_key, 3600, qa_id)  # 1å°æ—¶è¿‡æœŸ
    
    async def _get_cached_parent(self, trace_id: str) -> str:
        """è·å–ç¼“å­˜çš„parent_qa_id"""
        cache_key = f"qa:trace_parent:{trace_id}"
        return await self.redis.get(cache_key) or ""
```

#### 4.2.2 æ‰¹é‡å¯¼å…¥æ—¶

æ‰¹é‡å¯¼å…¥æ—¶å¯ä»¥ç›´æ¥å»ºç«‹å®Œæ•´çš„å½’å±å…³ç³»ï¼š

```python
async def import_from_trace(self, ...):
    """ä»traceè¡¨å¯¼å…¥ç«¯åˆ°ç«¯QA"""
    for trace in traces:
        # 1. åˆ›å»ºç«¯åˆ°ç«¯QA
        e2e_qa = self._trace_to_qa(trace, batch_id)
        e2e_qa["parent_qa_id"] = ""  # ç«¯åˆ°ç«¯ä»»åŠ¡æ²¡æœ‰parent
        await self.mq.publish("raw", e2e_qa, priority=0)
        
        # 2. å¯¼å…¥å…³è”çš„å­èŠ‚ç‚¹
        if include_sub_nodes:
            nodes = await self._query_nodes_by_trace(trace["trace_id"])
            for node in nodes:
                sub_qa = self._node_to_qa(node, batch_id)
                sub_qa["parent_qa_id"] = e2e_qa["qa_id"]  # è®¾ç½®å½’å±å…³ç³»
                await self.mq.publish("raw", sub_qa, priority=sub_qa["priority"])
```

### 4.3 å½’å±å…³ç³»åœ¨å‰ç«¯çš„å±•ç¤º

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä»»åŠ¡åˆ—è¡¨                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â–¼ ğŸ”´P0 ç°åœ¨å‡ ç‚¹äº†ï¼Ÿè¯·ä¿å­˜åˆ°time.txt                [E2E] [å¾…æ ‡æ³¨]       â”‚
â”‚    â”‚                                                                     â”‚
â”‚    â”œâ”€â”€ ğŸŸ¡P2 time_agent: è·å–å½“å‰æ—¶é—´              [Agent] [å¾…æ ‡æ³¨]      â”‚
â”‚    â”‚   â””â”€â”€ ğŸŸ¢P3 get_current_time: æŸ¥è¯¢æ—¶åŒºæ—¶é—´    [Tool]  [å·²å®Œæˆ]      â”‚
â”‚    â”‚                                                                     â”‚
â”‚    â””â”€â”€ ğŸŸ¡P2 file_agent: ä¿å­˜æ–‡ä»¶                  [Agent] [å¾…æ ‡æ³¨]      â”‚
â”‚        â””â”€â”€ ğŸŸ¢P3 write_file: å†™å…¥time.txt          [Tool]  [å·²å®Œæˆ]      â”‚
â”‚                                                                          â”‚
â”‚  â–¶ ğŸ”´P0 å¸®æˆ‘æŸ¥è¯¢è®¢å•çŠ¶æ€                          [E2E]   [è¿›è¡Œä¸­]      â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ äº”ã€é…ç½®é¡¹è®¾è®¡

### 5.1 å®Œæ•´é…ç½®é¡¹

```json
{
  "default": {
    "qa_annotation": {
      "enabled": false,
      "realtime_hook_enabled": false,
      
      "mq": {
        "type": "redis",
        "redis": {
          "stream_prefix": "qa",
          "consumer_group": "qa_processor",
          "max_len": 100000,
          "block_timeout_ms": 5000
        },
        "rabbitmq": {
          "host": "localhost",
          "port": 5672,
          "username": "guest",
          "password": "guest",
          "vhost": "/",
          "exchange": "qa_exchange",
          "prefetch_count": 10
        },
        "kafka": {
          "bootstrap_servers": "localhost:9092",
          "group_id": "qa_processor",
          "auto_offset_reset": "earliest"
        }
      },
      
      "collector": {
        "exclude_callees": ["retrieve_tools", "default_llm"],
        "exclude_callee_types": ["llm"],
        "min_question_length": 2,
        "min_answer_length": 10,
        "max_answer_length": 50000,
        "dedup_enabled": true,
        "dedup_cache_ttl_seconds": 86400
      },
      
      "llm_processor": {
        "enabled": true,
        "skip_if_disabled": true,
        "model": "default_llm",
        "batch_size": 10,
        "max_retries": 3,
        "retry_delay_seconds": 5,
        "quality_threshold": 0.3
      },
      
      "task": {
        "expire_hours": 24,
        "max_retry_count": 3,
        "priority_weights": {
          "e2e": 0,
          "user_agent": 1,
          "agent_agent": 2,
          "agent_tool": 3
        },
        "auto_assign": true,
        "assignment_strategy": "round_robin"
      },
      
      "review": {
        "enabled": true,
        "auto_approve_threshold": 0.9,
        "require_review_for_kb": true
      },
      
      "platform": {
        "page_size": 20,
        "enable_kb_export": true,
        "export_formats": ["json", "jsonl", "csv"]
      }
    }
  }
}
```

### 5.2 Configç±»æ‰©å±•

```python
# oxygent/config.py æ–°å¢æ–¹æ³•

class Config:
    # ... ç°æœ‰ä»£ç  ...
    
    """ qa_annotation """
    
    @classmethod
    def get_qa_annotation_config(cls) -> dict:
        return cls._config.get("qa_annotation", {})
    
    @classmethod
    def is_qa_annotation_enabled(cls) -> bool:
        return cls.get_qa_annotation_config().get("enabled", False)
    
    @classmethod
    def is_qa_realtime_hook_enabled(cls) -> bool:
        if not cls.is_qa_annotation_enabled():
            return False
        return cls.get_qa_annotation_config().get("realtime_hook_enabled", False)
    
    @classmethod
    def get_qa_mq_config(cls) -> dict:
        return cls.get_qa_annotation_config().get("mq", {})
    
    @classmethod
    def get_qa_mq_type(cls) -> str:
        return cls.get_qa_mq_config().get("type", "redis")
    
    @classmethod
    def get_qa_collector_config(cls) -> dict:
        return cls.get_qa_annotation_config().get("collector", {})
    
    @classmethod
    def get_qa_llm_processor_config(cls) -> dict:
        return cls.get_qa_annotation_config().get("llm_processor", {})
    
    @classmethod
    def is_qa_llm_processor_enabled(cls) -> bool:
        return cls.get_qa_llm_processor_config().get("enabled", True)
    
    @classmethod
    def get_qa_task_config(cls) -> dict:
        return cls.get_qa_annotation_config().get("task", {})
    
    @classmethod
    def get_qa_review_config(cls) -> dict:
        return cls.get_qa_annotation_config().get("review", {})
```

---

## ğŸ“¬ å…­ã€æ¶ˆæ¯é˜Ÿåˆ—æŠ½è±¡è®¾è®¡

### 6.1 MQæŠ½è±¡åŸºç±»

```mermaid
classDiagram
    class BaseMQ {
        <<abstract>>
        +connect() async
        +disconnect() async
        +publish(topic: str, data: dict, priority: int) async str
        +subscribe(topic: str, group: str, handler: Callable) async
        +ack(topic: str, group: str, message_id: str) async
        +nack(topic: str, group: str, message_id: str) async
        +get_pending_count(topic: str, group: str) async int
        +health_check() async bool
    }
    
    class RedisStreamMQ {
        -redis_client
        -stream_prefix: str
        -max_len: int
    }
    
    class RabbitMQ {
        -connection
        -channel
        -exchange: str
    }
    
    class KafkaMQ {
        -producer
        -consumer
        -bootstrap_servers: str
    }
    
    BaseMQ <|-- RedisStreamMQ
    BaseMQ <|-- RabbitMQ
    BaseMQ <|-- KafkaMQ
    
    class MQFactory {
        -_instance: BaseMQ
        +get_instance(mq_type: str) BaseMQ
        +reset()
    }
    
    MQFactory --> BaseMQ
```

### 6.2 MQåŸºç±»å®Œæ•´å®šä¹‰

```python
# oxygent/qa_annotation/mq/base_mq.py

from abc import ABC, abstractmethod
from typing import Callable, Any, Optional, List
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class MQMessage:
    """MQæ¶ˆæ¯å°è£…"""
    message_id: str
    topic: str
    data: dict
    priority: int = 0
    retry_count: int = 0
    created_at: str = ""


class BaseMQ(ABC):
    """æ¶ˆæ¯é˜Ÿåˆ—æŠ½è±¡åŸºç±»ï¼Œæ”¯æŒå¤šç§MQå®ç°"""
    
    @abstractmethod
    async def connect(self) -> None:
        """å»ºç«‹è¿æ¥"""
        pass
    
    @abstractmethod
    async def disconnect(self) -> None:
        """æ–­å¼€è¿æ¥"""
        pass
    
    @abstractmethod
    async def publish(
        self,
        topic: str,
        data: dict,
        priority: int = 0,
        delay_seconds: int = 0
    ) -> str:
        """
        å‘å¸ƒæ¶ˆæ¯
        
        Args:
            topic: ä¸»é¢˜åç§°ï¼ˆä¸å«å‰ç¼€ï¼‰
            data: æ¶ˆæ¯æ•°æ®
            priority: ä¼˜å…ˆçº§ï¼ˆ0æœ€é«˜ï¼‰
            delay_seconds: å»¶è¿Ÿå‘é€ç§’æ•°ï¼ˆç”¨äºé‡è¯•ï¼‰
            
        Returns:
            æ¶ˆæ¯ID
        """
        pass
    
    @abstractmethod
    async def subscribe(
        self,
        topic: str,
        group: str,
        handler: Callable[[MQMessage], Any],
        batch_size: int = 10,
    ) -> None:
        """
        è®¢é˜…æ¶ˆæ¯ï¼ˆConsumer Groupæ¨¡å¼ï¼‰
        
        Args:
            topic: ä¸»é¢˜åç§°
            group: æ¶ˆè´¹è€…ç»„åç§°
            handler: æ¶ˆæ¯å¤„ç†å‡½æ•°ï¼Œæ¥æ”¶MQMessageï¼Œè¿”å›å¤„ç†ç»“æœ
            batch_size: æ‰¹é‡å¤„ç†æ•°é‡
        """
        pass
    
    @abstractmethod
    async def ack(self, topic: str, group: str, message_id: str) -> None:
        """ç¡®è®¤æ¶ˆæ¯å·²æˆåŠŸå¤„ç†"""
        pass
    
    @abstractmethod
    async def nack(
        self,
        topic: str,
        group: str,
        message_id: str,
        requeue: bool = True
    ) -> None:
        """
        æ¶ˆæ¯å¤„ç†å¤±è´¥
        
        Args:
            topic: ä¸»é¢˜
            group: æ¶ˆè´¹è€…ç»„
            message_id: æ¶ˆæ¯ID
            requeue: æ˜¯å¦é‡æ–°å…¥é˜Ÿ
        """
        pass
    
    @abstractmethod
    async def get_pending_count(self, topic: str, group: str) -> int:
        """è·å–å¾…å¤„ç†æ¶ˆæ¯æ•°é‡"""
        pass
    
    @abstractmethod
    async def get_dead_letter_count(self) -> int:
        """è·å–æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯æ•°é‡"""
        pass
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            await self.get_pending_count("_health_check", "test")
            return True
        except Exception as e:
            logger.warning(f"MQ health check failed: {e}")
            return False
    
    async def publish_to_dead_letter(
        self,
        original_topic: str,
        data: dict,
        error: str
    ) -> str:
        """å‘å¸ƒåˆ°æ­»ä¿¡é˜Ÿåˆ—"""
        dead_letter_data = {
            "original_topic": original_topic,
            "original_data": data,
            "error": error,
            "failed_at": get_format_time(),
        }
        return await self.publish("dead_letter", dead_letter_data)
```

### 6.3 MQå·¥å‚ç±»

```python
# oxygent/mq_factory.py

from typing import Optional
from oxygent.config import Config
import logging

logger = logging.getLogger(__name__)


class MQFactory:
    """
    æ¶ˆæ¯é˜Ÿåˆ—å·¥å‚ç±»ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    ä½¿ç”¨ç¤ºä¾‹:
        mq = MQFactory().get_instance()
        await mq.publish("raw", {"question": "...", "answer": "..."})
    """
    
    _instance: Optional["MQFactory"] = None
    _mq_client = None
    _initialized = False
    
    def __new__(cls, *args, **kwargs):
        if not hasattr(cls, "_factory_instance"):
            cls._factory_instance = super().__new__(cls)
        return cls._factory_instance
    
    async def get_instance(self, mq_type: str = None, **kwargs):
        """
        è·å–MQå®ä¾‹ï¼ˆå¼‚æ­¥åˆå§‹åŒ–ï¼‰
        
        Args:
            mq_type: MQç±»å‹ï¼ˆredis/rabbitmq/kafkaï¼‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
            **kwargs: MQé…ç½®å‚æ•°ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„å€¼
            
        Returns:
            BaseMQå®ä¾‹
        """
        if self._mq_client is not None and self._initialized:
            return self._mq_client
        
        if mq_type is None:
            mq_type = Config.get_qa_mq_type()
        
        mq_config = Config.get_qa_mq_config().get(mq_type, {}).copy()
        mq_config.update(kwargs)
        
        if mq_type == "redis":
            from oxygent.qa_annotation.mq.redis_stream_mq import RedisStreamMQ
            self._mq_client = RedisStreamMQ(**mq_config)
        elif mq_type == "rabbitmq":
            from oxygent.qa_annotation.mq.rabbitmq import RabbitMQ
            self._mq_client = RabbitMQ(**mq_config)
        elif mq_type == "kafka":
            from oxygent.qa_annotation.mq.kafka_mq import KafkaMQ
            self._mq_client = KafkaMQ(**mq_config)
        else:
            raise ValueError(f"Unsupported MQ type: {mq_type}")
        
        # å»ºç«‹è¿æ¥
        await self._mq_client.connect()
        self._initialized = True
        
        logger.info(f"Initialized MQ client: {mq_type}")
        return self._mq_client
    
    def get_instance_sync(self) -> Optional["BaseMQ"]:
        """åŒæ­¥è·å–å·²åˆå§‹åŒ–çš„å®ä¾‹ï¼ˆç”¨äºéå¼‚æ­¥ä¸Šä¸‹æ–‡ï¼‰"""
        if not self._initialized:
            return None
        return self._mq_client
    
    async def close(self):
        """å…³é—­MQè¿æ¥"""
        if self._mq_client and self._initialized:
            await self._mq_client.disconnect()
            self._initialized = False
    
    def reset(self):
        """é‡ç½®MQå®ä¾‹ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        self._mq_client = None
        self._initialized = False
```

---

## ğŸ“Š ä¸ƒã€æ•°æ®é‡‡é›†æ¨¡å—è®¾è®¡

### 7.1 å®æ—¶Hooké›†æˆ

**æ³¨å…¥ä½ç½®**ï¼šåœ¨ `base_agent.py` çš„ `_post_save_data` æ–¹æ³•ä¸­ï¼š

```python
# oxygent/oxy/agents/base_agent.py

async def _post_save_data(self, oxy_response: OxyResponse):
    """Save complete trace and history data after processing."""
    await super()._post_save_data(oxy_response)
    oxy_request = oxy_response.oxy_request
    
    # ... ç°æœ‰çš„traceå’Œhistoryä¿å­˜é€»è¾‘ ...
    
    # QAæ ‡æ³¨å¹³å°Hook - åœ¨ESä¿å­˜å®Œæˆåè§¦å‘
    if Config.is_qa_realtime_hook_enabled():
        try:
            await self._publish_qa_to_mq(oxy_request, oxy_response)
        except Exception as e:
            # Hookå¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            logger.warning(f"QA annotation hook failed: {e}")

async def _publish_qa_to_mq(self, oxy_request: OxyRequest, oxy_response: OxyResponse):
    """å‘å¸ƒQAæ•°æ®åˆ°æ¶ˆæ¯é˜Ÿåˆ—"""
    from oxygent.qa_annotation.collectors.hook_collector import QACollectorHook
    
    hook = await QACollectorHook.get_instance()
    await hook.on_node_completed(oxy_request, oxy_response)
```

### 7.2 é‡‡é›†å™¨å®Œæ•´å®ç°

```python
# oxygent/qa_annotation/collectors/hook_collector.py

from typing import Optional
from oxygent.config import Config
from oxygent.mq_factory import MQFactory
from oxygent.schemas import OxyRequest, OxyResponse, OxyState
from oxygent.utils.common_utils import generate_uuid, get_format_time, get_md5
import logging

logger = logging.getLogger(__name__)


class QACollectorHook:
    """
    QAæ•°æ®å®æ—¶é‡‡é›†Hook
    
    åœ¨æ¯ä¸ªAgentèŠ‚ç‚¹æ‰§è¡Œå®Œæˆåè§¦å‘ï¼Œå°†QAæ•°æ®å‘å¸ƒåˆ°æ¶ˆæ¯é˜Ÿåˆ—ã€‚
    é€šè¿‡é…ç½®å¯æ§åˆ¶æ˜¯å¦å¯ç”¨ï¼Œä»¥åŠè¿‡æ»¤è§„åˆ™ã€‚
    """
    
    _instance: Optional["QACollectorHook"] = None
    
    @classmethod
    async def get_instance(cls) -> "QACollectorHook":
        if cls._instance is None:
            cls._instance = cls()
            await cls._instance._init()
        return cls._instance
    
    def __init__(self):
        self.config = Config.get_qa_collector_config()
        self.mq = None
        self.redis = None  # ç”¨äºç¼“å­˜traceæ˜ å°„
    
    async def _init(self):
        """å¼‚æ­¥åˆå§‹åŒ–"""
        self.mq = await MQFactory().get_instance()
        # è·å–Redisç”¨äºç¼“å­˜ï¼ˆå¤ç”¨ç°æœ‰è¿æ¥ï¼‰
        from oxygent.db_factory import DBFactory
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè·å–Rediså®¢æˆ·ç«¯
    
    async def on_node_completed(
        self,
        oxy_request: OxyRequest,
        oxy_response: OxyResponse
    ):
        """
        èŠ‚ç‚¹æ‰§è¡Œå®Œæˆæ—¶è§¦å‘
        
        Args:
            oxy_request: æ‰§è¡Œè¯·æ±‚
            oxy_response: æ‰§è¡Œå“åº”
        """
        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦é‡‡é›†
        if not self._should_collect(oxy_request, oxy_response):
            return
        
        # 2. æ„å»ºQAæ•°æ®
        qa_data = self._build_qa_data(oxy_request, oxy_response)
        
        # 3. å¤„ç†å½’å±å…³ç³»
        await self._handle_parent_relationship(qa_data)
        
        # 4. å‘å¸ƒåˆ°æ¶ˆæ¯é˜Ÿåˆ—
        try:
            message_id = await self.mq.publish(
                topic="raw",
                data=qa_data,
                priority=qa_data["priority"]
            )
            logger.debug(f"Published QA to MQ: {message_id}, qa_id={qa_data['qa_id']}")
        except Exception as e:
            logger.error(f"Failed to publish QA: {e}")
            raise
    
    def _should_collect(
        self,
        oxy_request: OxyRequest,
        oxy_response: OxyResponse
    ) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡‡é›†è¯¥QAå¯¹"""
        
        # 1. çŠ¶æ€å¿…é¡»æ˜¯æˆåŠŸ
        if oxy_response.state != OxyState.COMPLETED:
            return False
        
        # 2. æ’é™¤æŒ‡å®šçš„callee
        exclude_callees = self.config.get("exclude_callees", [])
        if oxy_request.callee in exclude_callees:
            return False
        
        # 3. æ’é™¤æŒ‡å®šç±»å‹
        exclude_types = self.config.get("exclude_callee_types", [])
        if oxy_request.callee_category in exclude_types:
            return False
        
        # 4. å¿…é¡»æœ‰æœ‰æ•ˆçš„query
        question = oxy_request.arguments.get("query", "")
        min_q_len = self.config.get("min_question_length", 2)
        if len(question) < min_q_len:
            return False
        
        # 5. ç­”æ¡ˆé•¿åº¦æ£€æŸ¥
        answer = str(oxy_response.output)
        min_a_len = self.config.get("min_answer_length", 10)
        max_a_len = self.config.get("max_answer_length", 50000)
        if len(answer) < min_a_len or len(answer) > max_a_len:
            return False
        
        return True
    
    def _build_qa_data(
        self,
        oxy_request: OxyRequest,
        oxy_response: OxyResponse
    ) -> dict:
        """æ„å»ºQAæ•°æ®ç»“æ„"""
        
        question = oxy_request.arguments.get("query", "")
        answer = str(oxy_response.output)
        qa_hash = get_md5(f"{question}:{answer}")
        
        priority = self._calculate_priority(oxy_request)
        source_type = self._get_source_type(oxy_request)
        
        return {
            # æ ‡è¯†
            "qa_id": generate_uuid(),
            "batch_id": "",  # å®æ—¶é‡‡é›†æ²¡æœ‰batch_id
            
            # QAå†…å®¹
            "question": question,
            "answer": answer,
            "qa_hash": qa_hash,
            
            # æ¥æºè¿½æº¯
            "source_type": source_type,
            "source_node_id": oxy_request.node_id,
            "source_trace_id": oxy_request.current_trace_id,
            "source_group_id": oxy_request.group_id,
            
            # è°ƒç”¨ä¿¡æ¯
            "caller": oxy_request.caller,
            "callee": oxy_request.callee,
            "caller_category": oxy_request.caller_category,
            "callee_category": oxy_request.callee_category,
            "call_chain": oxy_request.call_stack,
            
            # å½’å±å…³ç³»ï¼ˆåç»­å¤„ç†ï¼‰
            "parent_qa_id": "",
            
            # ä¼˜å…ˆçº§
            "priority": priority,
            
            # æ—¶é—´
            "created_at": get_format_time(),
        }
    
    def _calculate_priority(self, oxy_request: OxyRequest) -> int:
        """
        è®¡ç®—ä¼˜å…ˆçº§
        
        P0: ç«¯åˆ°ç«¯ï¼ˆç”¨æˆ·â†’ä¸»Agentï¼Œcall_stacké•¿åº¦ä¸º2ï¼‰
        P1: ç”¨æˆ·ç›´æ¥è°ƒç”¨å­Agent
        P2: Agentâ†’Agent
        P3: Agentâ†’Tool
        """
        weights = Config.get_qa_task_config().get("priority_weights", {
            "e2e": 0, "user_agent": 1, "agent_agent": 2, "agent_tool": 3
        })
        
        caller_category = oxy_request.caller_category
        callee_category = oxy_request.callee_category
        call_stack_len = len(oxy_request.call_stack)
        
        # ç”¨æˆ·å‘èµ·çš„è°ƒç”¨
        if caller_category == "user":
            if callee_category == "agent" and call_stack_len == 2:
                return weights.get("e2e", 0)  # P0
            return weights.get("user_agent", 1)  # P1
        
        # Agentè°ƒç”¨Agent
        if caller_category == "agent" and callee_category == "agent":
            return weights.get("agent_agent", 2)  # P2
        
        # Agentè°ƒç”¨Tool
        return weights.get("agent_tool", 3)  # P3
    
    def _get_source_type(self, oxy_request: OxyRequest) -> str:
        """è·å–æ•°æ®æºç±»å‹æ ‡è¯†"""
        caller_category = oxy_request.caller_category
        callee_category = oxy_request.callee_category
        call_stack_len = len(oxy_request.call_stack)
        
        if caller_category == "user":
            if callee_category == "agent" and call_stack_len == 2:
                return "e2e"
            return "user_agent"
        elif callee_category == "agent":
            return "agent_agent"
        return "agent_tool"
    
    async def _handle_parent_relationship(self, qa_data: dict):
        """
        å¤„ç†å½’å±å…³ç³»
        
        1. å¦‚æœæ˜¯ç«¯åˆ°ç«¯QAï¼Œç¼“å­˜trace_id â†’ qa_idçš„æ˜ å°„
        2. å¦‚æœæ˜¯å­QAï¼Œå°è¯•ä»ç¼“å­˜è·å–parent_qa_id
        """
        trace_id = qa_data["source_trace_id"]
        
        if qa_data["source_type"] == "e2e":
            # ç¼“å­˜æ˜ å°„å…³ç³»
            cache_key = f"qa:trace_parent:{trace_id}"
            cache_ttl = self.config.get("dedup_cache_ttl_seconds", 86400)
            
            if self.redis:
                await self.redis.setex(cache_key, cache_ttl, qa_data["qa_id"])
            
            qa_data["parent_qa_id"] = ""  # ç«¯åˆ°ç«¯æœ¬èº«æ²¡æœ‰parent
        else:
            # å°è¯•è·å–parent
            cache_key = f"qa:trace_parent:{trace_id}"
            
            if self.redis:
                parent_qa_id = await self.redis.get(cache_key)
                qa_data["parent_qa_id"] = parent_qa_id.decode() if parent_qa_id else ""
            else:
                qa_data["parent_qa_id"] = ""
```

### 7.3 å†å²æ•°æ®å¯¼å…¥å™¨

```python
# oxygent/qa_annotation/collectors/history_importer.py

from typing import List, Optional, Dict, Any
from datetime import datetime
from oxygent.config import Config
from oxygent.mq_factory import MQFactory
from oxygent.utils.common_utils import generate_uuid, get_format_time, get_md5
import json
import logging

logger = logging.getLogger(__name__)


class QAHistoryImporter:
    """
    ä»ESå†å²æ•°æ®æ‰¹é‡å¯¼å…¥QA
    
    æ”¯æŒä»traceè¡¨å’Œnodeè¡¨å¯¼å…¥æ•°æ®ï¼Œç”¨æˆ·å¯åœ¨æ ‡æ³¨å¹³å°ç•Œé¢ä¸Šæ“ä½œã€‚
    """
    
    def __init__(self, es_client, mq_client=None):
        self.es_client = es_client
        self.mq = mq_client
        self.app_name = Config.get_app_name()
        self.collector_config = Config.get_qa_collector_config()
    
    async def _ensure_mq(self):
        """ç¡®ä¿MQå®¢æˆ·ç«¯å·²åˆå§‹åŒ–"""
        if self.mq is None:
            self.mq = await MQFactory().get_instance()
    
    async def preview_import(
        self,
        start_time: str,
        end_time: str,
        include_trace: bool = True,
        include_node_agent: bool = True,
        include_node_tool: bool = False,
    ) -> Dict[str, int]:
        """
        é¢„è§ˆå¯¼å…¥æ•°æ®é‡
        
        Returns:
            å„æ•°æ®æºçš„æ•°é‡ç»Ÿè®¡
        """
        stats = {
            "trace_count": 0,
            "node_agent_count": 0,
            "node_tool_count": 0,
            "estimated_total": 0,
        }
        
        time_range = {"range": {"create_time": {"gte": start_time, "lte": end_time}}}
        
        if include_trace:
            trace_query = {"query": time_range, "size": 0}
            result = await self.es_client.search(f"{self.app_name}_trace", trace_query)
            stats["trace_count"] = result.get("hits", {}).get("total", {}).get("value", 0)
        
        if include_node_agent or include_node_tool:
            # æŸ¥è¯¢agentç±»å‹èŠ‚ç‚¹
            if include_node_agent:
                agent_query = {
                    "query": {
                        "bool": {
                            "must": [
                                time_range["range"],
                                {"term": {"node_type": "agent"}},
                                {"term": {"state": 3}}
                            ]
                        }
                    },
                    "size": 0
                }
                result = await self.es_client.search(f"{self.app_name}_node", agent_query)
                stats["node_agent_count"] = result.get("hits", {}).get("total", {}).get("value", 0)
            
            # æŸ¥è¯¢toolç±»å‹èŠ‚ç‚¹
            if include_node_tool:
                tool_query = {
                    "query": {
                        "bool": {
                            "must": [
                                time_range["range"],
                                {"term": {"node_type": "tool"}},
                                {"term": {"state": 3}}
                            ]
                        }
                    },
                    "size": 0
                }
                result = await self.es_client.search(f"{self.app_name}_node", tool_query)
                stats["node_tool_count"] = result.get("hits", {}).get("total", {}).get("value", 0)
        
        stats["estimated_total"] = (
            stats["trace_count"] +
            stats["node_agent_count"] +
            stats["node_tool_count"]
        )
        
        return stats
    
    async def import_data(
        self,
        start_time: str,
        end_time: str,
        include_trace: bool = True,
        include_node_agent: bool = True,
        include_node_tool: bool = False,
        include_sub_nodes: bool = True,
        limit: int = 1000,
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¯¼å…¥
        
        Args:
            start_time: å¼€å§‹æ—¶é—´ (YYYY-MM-DD HH:mm:ss)
            end_time: ç»“æŸæ—¶é—´
            include_trace: æ˜¯å¦å¯¼å…¥traceè¡¨
            include_node_agent: æ˜¯å¦å¯¼å…¥agentç±»å‹node
            include_node_tool: æ˜¯å¦å¯¼å…¥toolç±»å‹node
            include_sub_nodes: å¯¼å…¥traceæ—¶æ˜¯å¦åŒæ—¶å¯¼å…¥å…³è”çš„å­èŠ‚ç‚¹
            limit: æœ€å¤§å¯¼å…¥æ•°é‡
            
        Returns:
            å¯¼å…¥ç»“æœç»Ÿè®¡
        """
        await self._ensure_mq()
        
        batch_id = generate_uuid()
        stats = {
            "batch_id": batch_id,
            "trace_imported": 0,
            "node_imported": 0,
            "skipped": 0,
            "errors": 0,
            "started_at": get_format_time(),
        }
        
        # ç”¨äºè®°å½•å·²å¤„ç†çš„traceï¼Œé¿å…é‡å¤å¯¼å…¥å­èŠ‚ç‚¹
        processed_traces = set()
        # ç”¨äºè®°å½•trace_idåˆ°qa_idçš„æ˜ å°„
        trace_qa_mapping = {}
        
        try:
            # 1. å¯¼å…¥traceè¡¨æ•°æ®
            if include_trace:
                trace_result = await self._import_traces(
                    start_time, end_time, batch_id, limit,
                    include_sub_nodes, trace_qa_mapping, processed_traces
                )
                stats["trace_imported"] = trace_result["imported"]
                stats["node_imported"] += trace_result["sub_nodes"]
                stats["skipped"] += trace_result["skipped"]
            
            # 2. å¯¼å…¥nodeè¡¨æ•°æ®ï¼ˆæ’é™¤å·²é€šè¿‡traceå¯¼å…¥çš„ï¼‰
            remaining_limit = limit - stats["trace_imported"] - stats["node_imported"]
            if remaining_limit > 0 and (include_node_agent or include_node_tool):
                node_result = await self._import_nodes(
                    start_time, end_time, batch_id, remaining_limit,
                    include_node_agent, include_node_tool,
                    processed_traces, trace_qa_mapping
                )
                stats["node_imported"] += node_result["imported"]
                stats["skipped"] += node_result["skipped"]
        
        except Exception as e:
            logger.error(f"Import failed: {e}")
            stats["errors"] += 1
            raise
        
        stats["finished_at"] = get_format_time()
        stats["total_imported"] = stats["trace_imported"] + stats["node_imported"]
        
        return stats
    
    async def _import_traces(
        self,
        start_time: str,
        end_time: str,
        batch_id: str,
        limit: int,
        include_sub_nodes: bool,
        trace_qa_mapping: Dict[str, str],
        processed_traces: set,
    ) -> Dict[str, int]:
        """ä»traceè¡¨å¯¼å…¥"""
        
        result = {"imported": 0, "sub_nodes": 0, "skipped": 0}
        
        query = {
            "query": {
                "range": {
                    "create_time": {"gte": start_time, "lte": end_time}
                }
            },
            "size": limit,
            "sort": [{"create_time": {"order": "desc"}}]
        }
        
        es_result = await self.es_client.search(f"{self.app_name}_trace", query)
        traces = es_result.get("hits", {}).get("hits", [])
        
        for trace_hit in traces:
            trace = trace_hit["_source"]
            trace_id = trace.get("trace_id")
            
            # è§£æå¹¶éªŒè¯
            qa_data = self._trace_to_qa(trace, batch_id)
            if qa_data is None:
                result["skipped"] += 1
                continue
            
            # å‘å¸ƒåˆ°MQ
            await self.mq.publish("raw", qa_data, priority=0)
            result["imported"] += 1
            
            # è®°å½•æ˜ å°„å…³ç³»
            trace_qa_mapping[trace_id] = qa_data["qa_id"]
            processed_traces.add(trace_id)
            
            # å¯¼å…¥å…³è”çš„å­èŠ‚ç‚¹
            if include_sub_nodes:
                sub_count = await self._import_sub_nodes(
                    trace_id, batch_id, qa_data["qa_id"]
                )
                result["sub_nodes"] += sub_count
        
        return result
    
    async def _import_sub_nodes(
        self,
        trace_id: str,
        batch_id: str,
        parent_qa_id: str
    ) -> int:
        """å¯¼å…¥æŸä¸ªtraceä¸‹çš„æ‰€æœ‰å­èŠ‚ç‚¹"""
        
        query = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"trace_id": trace_id}},
                        {"term": {"state": 3}},  # COMPLETED
                    ],
                    "must_not": [
                        {"term": {"caller": "user"}}  # æ’é™¤userç›´æ¥è°ƒç”¨çš„ï¼ˆå·²åœ¨traceä¸­ï¼‰
                    ]
                }
            },
            "size": 1000,
            "sort": [{"create_time": {"order": "asc"}}]
        }
        
        result = await self.es_client.search(f"{self.app_name}_node", query)
        nodes = result.get("hits", {}).get("hits", [])
        
        count = 0
        for node_hit in nodes:
            node = node_hit["_source"]
            qa_data = self._node_to_qa(node, batch_id, parent_qa_id)
            
            if qa_data is not None:
                await self.mq.publish("raw", qa_data, priority=qa_data["priority"])
                count += 1
        
        return count
    
    async def _import_nodes(
        self,
        start_time: str,
        end_time: str,
        batch_id: str,
        limit: int,
        include_agent: bool,
        include_tool: bool,
        processed_traces: set,
        trace_qa_mapping: Dict[str, str],
    ) -> Dict[str, int]:
        """ä»nodeè¡¨å•ç‹¬å¯¼å…¥"""
        
        result = {"imported": 0, "skipped": 0}
        
        # æ„å»ºnode_typeè¿‡æ»¤
        node_types = []
        if include_agent:
            node_types.append("agent")
        if include_tool:
            node_types.append("tool")
        
        if not node_types:
            return result
        
        query = {
            "query": {
                "bool": {
                    "must": [
                        {"range": {"create_time": {"gte": start_time, "lte": end_time}}},
                        {"term": {"state": 3}},
                        {"terms": {"node_type": node_types}},
                    ]
                }
            },
            "size": limit,
            "sort": [{"create_time": {"order": "desc"}}]
        }
        
        es_result = await self.es_client.search(f"{self.app_name}_node", query)
        nodes = es_result.get("hits", {}).get("hits", [])
        
        for node_hit in nodes:
            node = node_hit["_source"]
            trace_id = node.get("trace_id")
            
            # è·³è¿‡å·²å¤„ç†çš„traceä¸‹çš„èŠ‚ç‚¹
            if trace_id in processed_traces:
                continue
            
            # å°è¯•è·å–parent_qa_id
            parent_qa_id = trace_qa_mapping.get(trace_id, "")
            
            qa_data = self._node_to_qa(node, batch_id, parent_qa_id)
            if qa_data is None:
                result["skipped"] += 1
                continue
            
            await self.mq.publish("raw", qa_data, priority=qa_data["priority"])
            result["imported"] += 1
        
        return result
    
    def _trace_to_qa(self, trace: dict, batch_id: str) -> Optional[dict]:
        """å°†traceè®°å½•è½¬æ¢ä¸ºQAæ•°æ®"""
        try:
            input_data = json.loads(trace.get("input", "{}"))
            question = input_data.get("query", "")
            answer = trace.get("output", "")
            
            # éªŒè¯
            min_q = self.collector_config.get("min_question_length", 2)
            min_a = self.collector_config.get("min_answer_length", 10)
            
            if len(question) < min_q or len(answer) < min_a:
                return None
            
            return {
                "qa_id": generate_uuid(),
                "batch_id": batch_id,
                "question": question,
                "answer": answer,
                "qa_hash": get_md5(f"{question}:{answer}"),
                "source_type": "e2e",
                "source_trace_id": trace.get("trace_id", ""),
                "source_node_id": "",
                "source_group_id": trace.get("group_id", ""),
                "caller": "user",
                "callee": trace.get("callee", ""),
                "caller_category": "user",
                "callee_category": "agent",
                "call_chain": ["user", trace.get("callee", "")],
                "parent_qa_id": "",  # ç«¯åˆ°ç«¯æ²¡æœ‰parent
                "priority": 0,
                "created_at": trace.get("create_time", get_format_time()),
            }
        except Exception as e:
            logger.warning(f"Parse trace error: {e}")
            return None
    
    def _node_to_qa(
        self,
        node: dict,
        batch_id: str,
        parent_qa_id: str = ""
    ) -> Optional[dict]:
        """å°†nodeè®°å½•è½¬æ¢ä¸ºQAæ•°æ®"""
        try:
            input_data = json.loads(node.get("input", "{}"))
            arguments = input_data.get("arguments", {})
            question = arguments.get("query", "")
            answer = node.get("output", "")
            
            # éªŒè¯
            min_q = self.collector_config.get("min_question_length", 2)
            min_a = self.collector_config.get("min_answer_length", 10)
            
            if len(question) < min_q or len(answer) < min_a:
                return None
            
            # è®¡ç®—ä¼˜å…ˆçº§
            caller = node.get("caller", "")
            node_type = node.get("node_type", "")
            
            if caller == "user":
                priority = 1
                source_type = "user_agent"
            elif node_type == "agent":
                priority = 2
                source_type = "agent_agent"
            else:
                priority = 3
                source_type = "agent_tool"
            
            return {
                "qa_id": generate_uuid(),
                "batch_id": batch_id,
                "question": question,
                "answer": answer,
                "qa_hash": get_md5(f"{question}:{answer}"),
                "source_type": source_type,
                "source_trace_id": node.get("trace_id", ""),
                "source_node_id": node.get("node_id", ""),
                "source_group_id": node.get("group_id", ""),
                "caller": caller,
                "callee": node.get("callee", ""),
                "caller_category": "agent" if caller != "user" else "user",
                "callee_category": node_type,
                "call_chain": node.get("call_stack", []),
                "parent_qa_id": parent_qa_id,
                "priority": priority,
                "created_at": node.get("create_time", get_format_time()),
            }
        except Exception as e:
            logger.warning(f"Parse node error: {e}")
            return None
```

---

## ğŸ’¾ å…«ã€æ•°æ®æ¨¡å‹è®¾è®¡

### 8.1 ESè¡¨ç»“æ„

#### QAä»»åŠ¡è¡¨ `{app}_qa_task`

```python
QA_TASK_MAPPING = {
    "mappings": {
        "properties": {
            # ä»»åŠ¡æ ‡è¯†
            "task_id": {"type": "keyword"},
            "qa_id": {"type": "keyword"},
            "batch_id": {"type": "keyword"},
            
            # QAå†…å®¹
            "question": {"type": "text"},
            "answer": {"type": "text"},
            "qa_hash": {"type": "keyword"},
            
            # æ¥æºè¿½æº¯
            "source_type": {"type": "keyword"},
            "source_node_id": {"type": "keyword"},
            "source_trace_id": {"type": "keyword"},
            "source_group_id": {"type": "keyword"},
            "call_chain": {"type": "keyword"},
            "parent_task_id": {"type": "keyword"},
            
            # ä¼˜å…ˆçº§ä¸åˆ†ç±»
            "priority": {"type": "integer"},
            "category": {"type": "keyword"},
            "tags": {"type": "keyword"},
            
            # LLMå¤„ç†ç»“æœ
            "llm_summary": {"type": "text"},
            "llm_quality_score": {"type": "float"},
            "llm_suggested_category": {"type": "keyword"},
            "llm_is_valid": {"type": "boolean"},
            
            # çŠ¶æ€ç®¡ç†
            "status": {"type": "keyword"},
            "stage": {"type": "keyword"},
            
            # ä»»åŠ¡åˆ†é…
            "assigned_to": {"type": "keyword"},
            "assigned_at": {"type": "date", "format": "yyyy-MM-dd HH:mm:ss||epoch_millis"},
            "expire_at": {"type": "date", "format": "yyyy-MM-dd HH:mm:ss||epoch_millis"},
            
            # æ—¶é—´æˆ³
            "created_at": {"type": "date", "format": "yyyy-MM-dd HH:mm:ss||epoch_millis"},
            "updated_at": {"type": "date", "format": "yyyy-MM-dd HH:mm:ss||epoch_millis"},
        }
    },
    "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0
    }
}
```

#### æ ‡æ³¨ç»“æœè¡¨ `{app}_qa_annotation`

```python
QA_ANNOTATION_MAPPING = {
    "mappings": {
        "properties": {
            "annotation_id": {"type": "keyword"},
            "task_id": {"type": "keyword"},
            
            # æ ‡æ³¨å†…å®¹
            "annotated_question": {"type": "text"},
            "annotated_answer": {"type": "text"},
            "quality_label": {"type": "keyword"},
            "is_useful": {"type": "boolean"},
            "correction_type": {"type": "keyword"},
            
            # åˆ†ç±»æ ‡æ³¨
            "domain": {"type": "keyword"},
            "intent": {"type": "keyword"},
            "complexity": {"type": "keyword"},
            
            # çŸ¥è¯†åº“
            "should_add_to_kb": {"type": "boolean"},
            "kb_category": {"type": "keyword"},
            
            # æ ‡æ³¨è€…
            "annotator_id": {"type": "keyword"},
            "annotation_time_cost": {"type": "integer"},
            
            # å®¡æ ¸
            "review_status": {"type": "keyword"},
            "reviewer_id": {"type": "keyword"},
            "review_comment": {"type": "text"},
            
            "created_at": {"type": "date", "format": "yyyy-MM-dd HH:mm:ss||epoch_millis"},
        }
    }
}
```

---

## ğŸ” ä¹ã€æ–¹æ¡ˆä¸è¶³ä¸å¾…ä¼˜åŒ–é¡¹

### 9.1 å½“å‰æ–¹æ¡ˆçš„ä¸è¶³

| é—®é¢˜ | æè¿° | å½±å“ | ä¼˜åŒ–å»ºè®® |
|------|------|------|----------|
| **åˆ†å¸ƒå¼ä¸€è‡´æ€§** | å®æ—¶Hookåœ¨å¤šå®ä¾‹éƒ¨ç½²æ—¶ï¼Œtraceæ˜ å°„ç¼“å­˜å¯èƒ½ä¸ä¸€è‡´ | å½’å±å…³ç³»å¯èƒ½ä¸å‡†ç¡® | ä½¿ç”¨Redisä½œä¸ºå…±äº«ç¼“å­˜ï¼Œæˆ–åœ¨LLMå¤„ç†é˜¶æ®µç»Ÿä¸€è¡¥å…¨ |
| **æ¶ˆæ¯é¡ºåº** | ç«¯åˆ°ç«¯ä»»åŠ¡å¯èƒ½æ™šäºå­ä»»åŠ¡åˆ°è¾¾MQ | å­ä»»åŠ¡æ— æ³•ç«‹å³å…³è”parent | LLMå¤„ç†å™¨å»¶è¿Ÿå¤„ç†ï¼Œç­‰å¾…parentæˆ–æ‰¹é‡å¤„ç†æ—¶è¡¥å…¨ |
| **æ­»ä¿¡å¤„ç†** | æ­»ä¿¡é˜Ÿåˆ—æ²¡æœ‰è‡ªåŠ¨é‡è¯•æœºåˆ¶ | éœ€è¦äººå·¥ä»‹å…¥ | å¢åŠ æ­»ä¿¡é˜Ÿåˆ—æ¶ˆè´¹è€…ï¼Œæ”¯æŒäººå·¥è§¦å‘é‡è¯• |
| **ç›‘æ§å‘Šè­¦** | ç¼ºå°‘Pipelineå„é˜¶æ®µçš„ç›‘æ§æŒ‡æ ‡ | é—®é¢˜éš¾ä»¥å‘ç° | é›†æˆPrometheus/Grafanaï¼Œå¢åŠ å…³é”®æŒ‡æ ‡ |
| **æ•°æ®å¯¼å‡º** | åªè®¾è®¡äº†å¯¼å…¥ï¼Œç¼ºå°‘å¯¼å‡ºæ ¼å¼å®šä¹‰ | è®­ç»ƒæ•°æ®ç”Ÿæˆä¸ä¾¿ | å¢åŠ JSONL/CSV/Parquetå¯¼å‡ºæ”¯æŒ |
| **æ‰¹é‡æ“ä½œ** | å‰ç«¯åªæ”¯æŒå•æ¡æ“ä½œ | æ•ˆç‡ä½ | å¢åŠ æ‰¹é‡æ ‡æ³¨ã€æ‰¹é‡å®¡æ ¸åŠŸèƒ½ |
| **LLMå¤„ç†å¯é€‰** | è™½ç„¶é…ç½®å¯å…³é—­ï¼Œä½†è·³è¿‡é€»è¾‘æœªå®Œæ•´å®ç° | é…ç½®é¡¹æ— æ•ˆ | åœ¨å¤„ç†å™¨ä¸­å®Œå–„skipé€»è¾‘ |

### 9.2 ç¬¬ä¸€æœŸMVPå»ºè®®ç®€åŒ–

ä¸ºäº†å¿«é€ŸéªŒè¯å’Œè¿­ä»£ï¼Œç¬¬ä¸€æœŸå¯ä»¥ç®€åŒ–ä»¥ä¸‹å†…å®¹ï¼š

1. **MQåªå®ç°Redis Streams**ï¼šRabbitMQ/Kafkaä½œä¸ºç¬¬äºŒæœŸ
2. **æš‚ä¸å®ç°LLMå¤„ç†å™¨**ï¼šç›´æ¥ä»rawåˆ°pendingï¼Œäººå·¥åˆ¤æ–­è´¨é‡
3. **ç®€åŒ–å®¡æ ¸æµç¨‹**ï¼šç¬¬ä¸€æœŸåªæ”¯æŒå®¡æ ¸é€šè¿‡/æ‹’ç»ï¼Œä¸æ”¯æŒå¤šçº§å®¡æ ¸
4. **ç®€åŒ–ç”¨æˆ·æƒé™**ï¼šåªåŒºåˆ†adminå’Œannotatorä¸¤ç§è§’è‰²
5. **å½’å±å…³ç³»ç®€åŒ–**ï¼šåªåœ¨æ‰¹é‡å¯¼å…¥æ—¶å»ºç«‹ï¼Œå®æ—¶Hookæš‚ä¸å¤„ç†

### 9.3 åç»­ä¼˜åŒ–è·¯çº¿å›¾

```mermaid
gantt
    title QAæ ‡æ³¨å¹³å°ä¼˜åŒ–è·¯çº¿å›¾
    dateFormat  YYYY-MM-DD
    section ç¬¬ä¸€æœŸ
    åŸºç¡€Pipeline          :a1, 2025-01-01, 14d
    ç®€å•æ ‡æ³¨ç•Œé¢          :a2, after a1, 7d
    section ç¬¬äºŒæœŸ
    LLMå¤„ç†å™¨            :b1, after a2, 7d
    å®¡æ ¸æµç¨‹å®Œå–„          :b2, after b1, 5d
    ç”¨æˆ·æƒé™ç®¡ç†          :b3, after b2, 3d
    section ç¬¬ä¸‰æœŸ
    RabbitMQ/Kafkaé€‚é…    :c1, after b3, 7d
    ç›‘æ§å‘Šè­¦              :c2, after c1, 5d
    æ•°æ®å¯¼å‡º              :c3, after c2, 3d
    section ç¬¬å››æœŸ
    çŸ¥è¯†åº“é›†æˆ            :d1, after c3, 7d
    æ‰¹é‡æ“ä½œ              :d2, after d1, 5d
```

---

## ğŸ“ åã€ç›®å½•ç»“æ„

```
oxygent/
â”œâ”€â”€ qa_annotation/                    # QAæ ‡æ³¨å¹³å°æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ schemas/                      # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ messages.py               # MQæ¶ˆæ¯å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ task.py                   # ä»»åŠ¡Schema
â”‚   â”‚   â”œâ”€â”€ annotation.py             # æ ‡æ³¨ç»“æœSchema
â”‚   â”‚   â””â”€â”€ user.py                   # ç”¨æˆ·Schema
â”‚   â”œâ”€â”€ collectors/                   # æ•°æ®é‡‡é›†å™¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ hook_collector.py         # å®æ—¶Hook
â”‚   â”‚   â””â”€â”€ history_importer.py       # å†å²æ•°æ®å¯¼å…¥
â”‚   â”œâ”€â”€ mq/                           # æ¶ˆæ¯é˜Ÿåˆ—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_mq.py                # MQæŠ½è±¡åŸºç±»
â”‚   â”‚   â”œâ”€â”€ redis_stream_mq.py        # Redis Streamså®ç°
â”‚   â”‚   â”œâ”€â”€ rabbitmq.py               # RabbitMQå®ç°ï¼ˆç¬¬äºŒæœŸï¼‰
â”‚   â”‚   â””â”€â”€ kafka_mq.py               # Kafkaå®ç°ï¼ˆç¬¬äºŒæœŸï¼‰
â”‚   â”œâ”€â”€ processors/                   # Pipelineå¤„ç†å™¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_processor.py         # å¤„ç†å™¨åŸºç±»
â”‚   â”‚   â”œâ”€â”€ llm_processor.py          # LLMå¤„ç†å™¨
â”‚   â”‚   â”œâ”€â”€ task_dispatcher.py        # ä»»åŠ¡åˆ†é…å™¨
â”‚   â”‚   â”œâ”€â”€ review_handler.py         # å®¡æ ¸å¤„ç†å™¨
â”‚   â”‚   â””â”€â”€ kb_publisher.py           # çŸ¥è¯†åº“å‘å¸ƒå™¨
â”‚   â”œâ”€â”€ services/                     # ä¸šåŠ¡æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ task_service.py           # ä»»åŠ¡æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ annotation_service.py     # æ ‡æ³¨æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ import_service.py         # å¯¼å…¥æœåŠ¡
â”‚   â”‚   â””â”€â”€ stats_service.py          # ç»Ÿè®¡æœåŠ¡
â”‚   â”œâ”€â”€ schedulers/                   # å®šæ—¶ä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ expired_task_handler.py   # è¿‡æœŸä»»åŠ¡å¤„ç†
â”‚   â”‚   â””â”€â”€ dead_letter_handler.py    # æ­»ä¿¡å¤„ç†
â”‚   â”œâ”€â”€ routes.py                     # APIè·¯ç”±
â”‚   â””â”€â”€ web/                          # å‰ç«¯èµ„æº
â”‚       â”œâ”€â”€ index.html
â”‚       â”œâ”€â”€ annotate.html
â”‚       â”œâ”€â”€ import.html
â”‚       â”œâ”€â”€ dashboard.html
â”‚       â”œâ”€â”€ css/
â”‚       â””â”€â”€ js/
â”œâ”€â”€ mq_factory.py                     # MQå·¥å‚
â””â”€â”€ config.py                         # æ–°å¢qa_annotationé…ç½®
```

---

## ğŸš€ åä¸€ã€å®æ–½è®¡åˆ’

### ç¬¬ä¸€æœŸï¼ˆ2-3å‘¨ï¼‰ï¼šMVPæ ¸å¿ƒæµç¨‹

| ä»»åŠ¡ | å·¥æœŸ | ä¼˜å…ˆçº§ | äº§å‡º |
|------|------|--------|------|
| Configæ‰©å±• | 0.5å¤© | P0 | config.pyæ–°å¢æ–¹æ³• |
| MQæŠ½è±¡åŸºç±» | 1å¤© | P0 | base_mq.py |
| Redis Streamså®ç° | 1.5å¤© | P0 | redis_stream_mq.py |
| MQå·¥å‚ç±» | 0.5å¤© | P0 | mq_factory.py |
| å®æ—¶Hooké‡‡é›†å™¨ | 1.5å¤© | P0 | hook_collector.py |
| å†å²æ•°æ®å¯¼å…¥å™¨ | 2å¤© | P0 | history_importer.py |
| ESè¡¨ç»“æ„åˆ›å»º | 0.5å¤© | P0 | schemas/ |
| ä»»åŠ¡åˆ†é…å™¨ï¼ˆç®€åŒ–ï¼‰ | 1å¤© | P0 | task_dispatcher.py |
| å¯¼å…¥API | 1å¤© | P0 | routes.py |
| ä»»åŠ¡åˆ—è¡¨API | 1å¤© | P0 | routes.py |
| æ ‡æ³¨æäº¤API | 1å¤© | P0 | routes.py |
| å¯¼å…¥é¡µé¢ | 1.5å¤© | P1 | import.html |
| ä»»åŠ¡åˆ—è¡¨é¡µé¢ | 1.5å¤© | P1 | index.html |
| æ ‡æ³¨é¡µé¢ | 2å¤© | P1 | annotate.html |

### ç¬¬äºŒæœŸï¼ˆ2å‘¨ï¼‰ï¼šå®Œå–„ä½“éªŒ

| ä»»åŠ¡ | å·¥æœŸ | äº§å‡º |
|------|------|------|
| LLMå¤„ç†å™¨ | 2å¤© | llm_processor.py |
| å®¡æ ¸æµç¨‹ | 2å¤© | review_handler.py |
| è¿‡æœŸä»»åŠ¡å¤„ç† | 1å¤© | expired_task_handler.py |
| ç»Ÿè®¡Dashboard | 2å¤© | dashboard.html |
| ç”¨æˆ·è§’è‰²æƒé™ | 1.5å¤© | userç›¸å…³ |

### ç¬¬ä¸‰æœŸï¼ˆ2å‘¨ï¼‰ï¼šç”Ÿäº§ä¼˜åŒ–

| ä»»åŠ¡ | å·¥æœŸ | äº§å‡º |
|------|------|------|
| RabbitMQé€‚é…å™¨ | 2å¤© | rabbitmq.py |
| ç›‘æ§æŒ‡æ ‡ | 1.5å¤© | é›†æˆPrometheus |
| æ•°æ®å¯¼å‡º | 1.5å¤© | å¯¼å‡ºåŠŸèƒ½ |
| æ­»ä¿¡é˜Ÿåˆ—å¤„ç† | 1å¤© | dead_letter_handler.py |
| æ‰¹é‡æ“ä½œ | 2å¤© | æ‰¹é‡åŠŸèƒ½ |

---

## âœ… åäºŒã€æ€»ç»“

æœ¬è®¾è®¡æ–¹æ¡ˆv2.1é’ˆå¯¹ç”¨æˆ·åé¦ˆè¿›è¡Œäº†ä»¥ä¸‹ä¼˜åŒ–ï¼š

### 12.1 æ–°å¢å†…å®¹

1. **Topicè®¾è®¡è¯¦è§£**ï¼šæ˜ç¡®äº†6ä¸ªTopicçš„èŒè´£ã€ç”Ÿäº§è€…ã€æ¶ˆè´¹è€…å’Œæ¶ˆæ¯æ ¼å¼
2. **Pipelineæµè½¬è§„åˆ™**ï¼šè¯¦ç»†æè¿°äº†æ¯ä¸ªé˜¶æ®µçš„å¤„ç†é€»è¾‘å’Œè¾“å‡ºè§„åˆ™
3. **ä¼˜å…ˆçº§è®¡ç®—é€»è¾‘**ï¼šæä¾›äº†å®Œæ•´çš„ä»£ç å®ç°å’Œåˆ¤æ–­è§„åˆ™
4. **å½’å±å…³ç³»æœºåˆ¶**ï¼š
   - å®æ—¶Hooké‡‡é›†æ—¶çš„å»¶è¿Ÿå…³è”æ–¹æ¡ˆ
   - æ‰¹é‡å¯¼å…¥æ—¶çš„å³æ—¶å…³è”æ–¹æ¡ˆ
   - ä½¿ç”¨Redisç¼“å­˜trace_idåˆ°qa_idçš„æ˜ å°„
5. **æ–¹æ¡ˆä¸è¶³åˆ†æ**ï¼šå®¢è§‚åˆ—å‡ºäº†å½“å‰è®¾è®¡çš„ä¸è¶³å’Œä¼˜åŒ–å»ºè®®
6. **MVPç®€åŒ–å»ºè®®**ï¼šä¸ºå¿«é€ŸéªŒè¯æä¾›äº†ç®€åŒ–æ–¹æ¡ˆ

### 12.2 å…³é”®è®¾è®¡å†³ç­–

1. **æ•°æ®æº**ï¼štraceè¡¨ç”¨äºP0ç«¯åˆ°ç«¯QAï¼Œnodeè¡¨ç”¨äºP1-P3å­ä»»åŠ¡QA
2. **å½’å±å…³ç³»**ï¼šé€šè¿‡trace_idå…³è”ï¼Œä½¿ç”¨Redisç¼“å­˜åŠ é€ŸæŸ¥æ‰¾
3. **ä¼˜å…ˆçº§**ï¼šP0 > P1 > P2 > P3ï¼Œæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
4. **MQæŠ½è±¡**ï¼šæ”¯æŒRedis/RabbitMQ/Kafkaåˆ‡æ¢ï¼Œç¬¬ä¸€æœŸåªå®ç°Redis

### 12.3 åç»­ä»£ç ç”Ÿæˆæ³¨æ„äº‹é¡¹

1. ä»£ç ä¸­çš„`...`å ä½ç¬¦éœ€è¦æ›¿æ¢ä¸ºå®é™…å®ç°
2. å¼‚å¸¸å¤„ç†éœ€è¦å®Œå–„
3. æ—¥å¿—è®°å½•éœ€è¦ç»Ÿä¸€æ ¼å¼
4. å•å…ƒæµ‹è¯•éœ€è¦åŒæ­¥ç¼–å†™
